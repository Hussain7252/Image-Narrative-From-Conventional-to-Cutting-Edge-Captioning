{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1111676,"sourceType":"datasetVersion","datasetId":623289},{"sourceId":8187467,"sourceType":"datasetVersion","datasetId":4848194}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#dependencies\n\n!pip install datasets\n!pip install accelerate\n!pip install rouge\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imports\n\nimport os\nimport datasets\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport multiprocessing as mp\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom rouge import Rouge\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import io, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom transformers import Seq2SeqTrainer ,Seq2SeqTrainingArguments\nfrom transformers import VisionEncoderDecoderModel , ViTFeatureExtractor\nfrom transformers import AutoTokenizer ,  GPT2Config , default_data_collator\n\n\nif torch.cuda.is_available():\n\n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# configuration class \n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nclass config :\n    ENCODER = \"google/vit-base-patch16-224\"\n    DECODER = \"gpt2\"\n    TRAIN_BATCH_SIZE = 8\n    VAL_BATCH_SIZE = 8\n    VAL_EPOCHS = 1\n    LR = 5e-5\n    SEED = 42\n    MAX_LEN = 128\n    SUMMARY_LEN = 20\n    WEIGHT_DECAY = 0.01\n    MEAN = (0.485, 0.456, 0.406)\n    STD = (0.229, 0.224, 0.225)\n    TRAIN_PCT = 0.95\n    NUM_WORKERS = mp.cpu_count()\n    EPOCHS = 3\n    IMG_SIZE = (224,224)\n    LABEL_MASK = -100\n    TOP_K = 1000\n    TOP_P = 0.95\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T02:14:43.375495Z","iopub.execute_input":"2024-04-23T02:14:43.375971Z","iopub.status.idle":"2024-04-23T02:14:43.383503Z","shell.execute_reply.started":"2024-04-23T02:14:43.375936Z","shell.execute_reply":"2024-04-23T02:14:43.382331Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#helper function to build tokens\n\ndef build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n    return outputs\nAutoTokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens","metadata":{"execution":{"iopub.status.busy":"2024-04-23T02:14:47.783123Z","iopub.execute_input":"2024-04-23T02:14:47.783564Z","iopub.status.idle":"2024-04-23T02:14:47.789180Z","shell.execute_reply.started":"2024-04-23T02:14:47.783529Z","shell.execute_reply":"2024-04-23T02:14:47.788061Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"rouge = Rouge()\n\n#function for calculate the rouge L metric\ndef compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    # all unnecessary tokens are removed\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.get_scores(pred_str, label_str)[0]['rouge-l']\n\n    return {\n        \"rougeL_precision\": rouge_output['p'],\n        \"rougeL_recall\": rouge_output['r'],\n        \"rougeL_fmeasure\": rouge_output['f'],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:43:00.557735Z","iopub.execute_input":"2024-04-22T18:43:00.558105Z","iopub.status.idle":"2024-04-22T18:43:00.564634Z","shell.execute_reply.started":"2024-04-22T18:43:00.558076Z","shell.execute_reply":"2024-04-22T18:43:00.563630Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#loading feature extractor and tokenizer from pretrained models\n\nfeature_extractor = ViTFeatureExtractor.from_pretrained(config.ENCODER)\ntokenizer = AutoTokenizer.from_pretrained(config.DECODER)\ntokenizer.pad_token = tokenizer.unk_token","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image transform used for processing\nflickr_transform = transforms.Compose(\n    [\n        transforms.Resize(config.IMG_SIZE),\n        transforms.ToTensor(),\n    ]\n)\n\n\n#data split\ndf=  pd.read_csv(\"/kaggle/input/flickr/captions.txt\")\ntrain_df , val_df = train_test_split(df , test_size = 0.2)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:43:08.627161Z","iopub.execute_input":"2024-04-22T18:43:08.627549Z","iopub.status.idle":"2024-04-22T18:43:08.697319Z","shell.execute_reply.started":"2024-04-22T18:43:08.627520Z","shell.execute_reply":"2024-04-22T18:43:08.696424Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                       image  \\\n0  1000268201_693b08cb0e.jpg   \n1  1000268201_693b08cb0e.jpg   \n2  1000268201_693b08cb0e.jpg   \n3  1000268201_693b08cb0e.jpg   \n4  1000268201_693b08cb0e.jpg   \n\n                                             caption  \n0  A child in a pink dress is climbing up a set o...  \n1              A girl going into a wooden building .  \n2   A little girl climbing into a wooden playhouse .  \n3  A little girl climbing the stairs to her playh...  \n4  A little girl in a pink dress going into a woo...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A child in a pink dress is climbing up a set o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A girl going into a wooden building .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing into a wooden playhouse .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing the stairs to her playh...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl in a pink dress going into a woo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#class used for image processing\n\nclass ImgDataset(Dataset):\n    def __init__(self, df,root_dir,tokenizer,feature_extractor, transform = None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n        self.tokenizer= tokenizer\n        self.feature_extractor = feature_extractor\n        self.max_length = 50\n    def __len__(self,):\n        return len(self.df)\n    def __getitem__(self,idx):\n        caption = self.df.caption.iloc[idx]\n        image = self.df.image.iloc[idx]\n        img_path = os.path.join(self.root_dir , image)\n        img = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform is not None:\n            im= self.transform(img)\n          \n        pixel_values = self.feature_extractor(im, return_tensors=\"pt\").pixel_values\n        captions = self.tokenizer(caption,padding='max_length',max_length=self.max_length).input_ids\n        captions = [caption if caption != self.tokenizer.pad_token_id else -100 for caption in captions]\n        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(captions)}\n        return encoding\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T02:15:05.240252Z","iopub.execute_input":"2024-04-23T02:15:05.240646Z","iopub.status.idle":"2024-04-23T02:15:05.250469Z","shell.execute_reply.started":"2024-04-23T02:15:05.240617Z","shell.execute_reply":"2024-04-23T02:15:05.249231Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#load data\n\ntrain_dataset = ImgDataset(train_df, root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor ,transform = flickr_transform)\nval_dataset = ImgDataset(val_df , root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor , transform  = flickr_transform)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:43:20.747999Z","iopub.execute_input":"2024-04-22T18:43:20.748396Z","iopub.status.idle":"2024-04-22T18:43:20.753418Z","shell.execute_reply.started":"2024-04-22T18:43:20.748365Z","shell.execute_reply":"2024-04-22T18:43:20.752419Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#load model\n\nmodel = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(config.ENCODER, config.DECODER)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining model parameters\n\nmodel.config.decoder_start_token_id = tokenizer.cls_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n# make sure vocab size is set correctly\nmodel.config.vocab_size = model.config.decoder.vocab_size\n# set beam search parameters\nmodel.config.eos_token_id = tokenizer.sep_token_id\nmodel.config.decoder_start_token_id = tokenizer.bos_token_id\nmodel.config.max_length = 128\nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 4","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:43:25.874581Z","iopub.execute_input":"2024-04-22T18:43:25.875299Z","iopub.status.idle":"2024-04-22T18:43:25.881431Z","shell.execute_reply.started":"2024-04-22T18:43:25.875263Z","shell.execute_reply":"2024-04-22T18:43:25.880398Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#training arguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir='VIT_large_gpt2',\n    per_device_train_batch_size=config.TRAIN_BATCH_SIZE,\n    per_device_eval_batch_size=config.VAL_BATCH_SIZE,\n    predict_with_generate=True,\n    evaluation_strategy=\"epoch\",\n    do_train=True,\n    do_eval=True,\n    logging_steps=1024,\n    save_steps=800,\n    warmup_steps=1024,\n    learning_rate = 5e-5,\n    #max_steps=1500, # delete for full training\n    num_train_epochs = config.EPOCHS, #TRAIN_EPOCHS\n    overwrite_output_dir=True,\n    save_total_limit=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:43:27.801194Z","iopub.execute_input":"2024-04-22T18:43:27.801833Z","iopub.status.idle":"2024-04-22T18:43:27.811091Z","shell.execute_reply.started":"2024-04-22T18:43:27.801804Z","shell.execute_reply":"2024-04-22T18:43:27.810251Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    tokenizer=feature_extractor,\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=default_data_collator,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:43:30.459938Z","iopub.execute_input":"2024-04-22T18:43:30.460323Z","iopub.status.idle":"2024-04-23T01:19:09.835541Z","shell.execute_reply.started":"2024-04-22T18:43:30.460292Z","shell.execute_reply":"2024-04-23T01:19:09.834471Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12138' max='12138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12138/12138 6:35:38, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rougel Precision</th>\n      <th>Rougel Recall</th>\n      <th>Rougel Fmeasure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.896700</td>\n      <td>2.785194</td>\n      <td>0.065217</td>\n      <td>0.300000</td>\n      <td>0.107143</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.657400</td>\n      <td>2.728507</td>\n      <td>0.071429</td>\n      <td>0.300000</td>\n      <td>0.115385</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.495900</td>\n      <td>2.726482</td>\n      <td>0.065217</td>\n      <td>0.300000</td>\n      <td>0.107143</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nYour generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nYour generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nYour generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nYour generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nYour generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1197: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 128, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=12138, training_loss=2.7306522074592703, metrics={'train_runtime': 23738.7052, 'train_samples_per_second': 4.09, 'train_steps_per_second': 0.511, 'total_flos': 1.7521600116635468e+19, 'train_loss': 2.7306522074592703, 'epoch': 3.0})"},"metadata":{}}]}]}